\chapter{Background}
\label{chap:background}

\section{Clojure}

Clojure is a dynamic language for the Java Virtual Machine, with a compelling
combination of features: Clojure is elegant. Clojure's clean, careful design
lets you write programs that get right to the essence of a problem, without a
lot of clutter and ceremony. Clojure is Lisp reloaded. Clojure has the power
inherent in Lisp, but is not constrained by the history of Lisp. Clojure is a
functional language. Data structures are immutable, and functions tend to be
side-effect free. This makes it easier to write correct programs, and to compose
large programs from smaller ones. Clojure is concurrent. Rather than error-prone
locking, Clojure provides software transactional memory. Clojure embraces Java.
Calling from Clojure to Java is direct, and goes through no translation layer.
Clojure is fast. Wherever you need it, you can get the exact same performance
that you could get from hand-written Java code. Many other languages offer some
of these features, but the combination of them all makes Clojure sparkle.

For me first of all it is enjoyable, but if we talk about some boring enterprise
things: customers and stakeholders have substantial investments in and are
already comfortable with the performance, security and stability of
industry-standard platforms like the JVM. While Java developers may envy the
succinctness, flexibility and productivity of dynamic languages, they have
concerns about running on customer-approved infrastructure, access to their
existing code base and libraries, and performance.

Immutability and STM. In addition, they face ongoing problems dealing with
concurrency using native threads and locking. Clojure is an effort in pragmatic
dynamic language design in this context. It is created to be a general-purpose
language suitable in those areas where Java is suitable. It reflects the reality
that, for the concurrent programming future, pervasive, unmoderated mutation
simply has to go.

Clojure meets its goals by: embracing an industry-standard, open platform - the
JVM, modernizing a venerable language - Lisp, fostering functional programming
with immutable persistent data structures, and providing built-in concurrency
support via software transactional memory and asynchronous agents. The result is
robust, practical, and fast.

We can't handle power of machines with current languages. Java and OO stuff is
so complicated you can't refactor it and you can't fix it (Dave Thomas). It
means that it is easier to buy more cheap hardware and use some tools, which
maybe not so lightweight, but allows to create pretty simple architectures.

Another very important feature of the Clojure is a community. The community is
friendly, helpful and pretty smart. Most of the ideas implemented in other
languages have their own implementation in Clojure(Script). For example go
channels implemented as core.async library. React.js implemented at least in 4
ClojureScript “frameworks”: Reagent, om, om.next, Rum. Also, there are many
helpful resources and training courses already created.

Modern implementation of venerable lisp with advanced concurrency support on
mature enterprise ready platforms. It at least deserves attention. Finding
missing parts of such a great tool is a good contribution. More extensive
explanation about language and it's features can be found in
\cite{halloway2009programming}, \cite{fogus2011joy} and
\cite{hickey2008clojure}.


\section{Live programming}

There are two ways a do-it-yourselfer might replace an old lightswitch with a
dimmer: (1) first turn off the circuit breaker, or (2) wire it hot. Hot wiring
has two advantages: it’s probably faster, and in some cases it may be easier to
tell which wire is which by touching them to a light bulb or voltmeter. However,
hot wiring is dangerous.

In programming, working live need not be dangerous, and the opportunity it
offers for immediate feedback can be very valuable. Here are some of the
motivations for liveness in programming:

\begin{itemize}
\item minimizing the latency between a programming action and seeing its effect
  on program execution.
\item allowing performances in which programmer actions control the dynamics of
  the audience experience in real time.
\item simplifying the “credit assignment problem” faced by a programmer when
  some programming actions induce a new runtime behavior (such as a bug).
\item supporting learning (hence the early connections between liveness with
  visual programming and program visualization).
\end{itemize}

The traditional program development cycle involved the four separate phases:
edit, compile, link, run. Debugging sometimes altered the cycle by changing the
run mode to include setting breakpoints, single-stepping, etc. Changing a
program while it was being executed was rare outside of debugging sessions, and
the changes made during debugging were more often to data values than machine
code. Changes to the code were difficult to make, and when they were made, it
was generally while execution was suspended at a breakpoint. Live programming
was very much an exception to the norm.

In live programming, there is only one phase, at least in principle. The phase
involves the program constantly running, even as various editing events occur. A
system that supports live programming need not require that all programming
performed within the system be live. At times, live programming is unnecessary
and the execution of the program might be distracting, particularly when the
program is in an intermediate state between useful versions with meaningful
behavior.

In modern integrated development environments such as Eclipse for Java
programming, there are many features that work as the programmer codes, to
provide feedback to the programmer. These include syntax highlighting, code
completion suggestions, and indications of problems associated with various
locations in a source file. Facilities for editing running code also exist. The
Java virtual machine from version 1.4 has included a “hot-swap” feature that
enables the replacement of a class file by a new one while the overall program
is running. That permits IDEs to offer a code “push” feature to quickly compile
a new version of a class and/or object and insert it into the running JVM. When
programmers code live, their behavior may be different than without liveness,
and this can lead to new means to infer structures such as unit tests. About
future of live development Tanimoto and Steven L. talk in the
\cite{tanimoto2013perspective}.

Clojure is pretty good for live programming and rapid development as it uses
REPL (read eval print loop, like interactive command shell), has a good explicit
state management and it also suitable for TDD (test driven development) as it
has immutable and pure functional nature. Those workflows give huge productivity
boost \cite{madeyski2007impact}, \cite{tanimoto2013perspective}, that is why it
necessary to keep in mind this workflows when think about possible solutions.


\section{Static type checking}
It is necessary to understand what advantages and disadvantages static type
checking has. First of all to understand what benefits can be taken and secondly
what can be and should be avoided. This also


\subsection{Advantages}
A large class of errors are caught, earlier in the development process, closer
to the location where they are introduced. Example: you have a map whose keys
are strings and whose values you expect (elsewhere in your program) to be
functions from Int -> Int, and you accidentally insert a function that returns a
list of integers. Oops! With static typing, this error would be caught by the
typechecker and pointed out to the programmer at the location the erroneous
value is inserted. In a dynamic language, the error could go unnoticed until
much later, when that value gets pulled out of the map and the function applied.
As another example of this sort of thing, many languages have a concept of null
(the ‘billion dollar mistake’). Even static languages like Java allow null to be
used in place of any type, which leads to a situations where unexpected null
values pop up in your program very far from the place where they were
erroneously introduced.

The types guide development and can even write code for you—the programmer ends
up with less to specify. Example: Haskell has a feature called typeclasses,
which derives aspects of your program, purely based on the types, which are
often inferred. The resulting code can be noticeably shorter than dynamic
languages which cannot disambiguate programmer intent via types. More advanced
dependently typed languages routinely derive large amounts of boring code with
guidance from the programmer and the types specified. Conor McBride likes to
emphasize that types are not merely about preventing errors—they are about
declaring more of your intent to the machine so the machine can do more work on
your behalf.

One can refactor with greater confidence, since a large class of errors
introduced during refactoring will end up as type errors. Example: you have a
function that currently returns a single number, and wish to modify it to return
a list of numbers. In a static language, updating the declared type signature
and fixing any compile errors will catch most, if not all places that need
updating.

Static types can ease the mental burden of writing programs, by automatically
tracking information the programmer would otherwise have to track mentally in
some fashion. Example: you are writing a tricky function, and have two values in
scope, f and x. The f you pulled out of a dictionary, the x was the result of
calling foo(23). Is it safe to call f(x)? Types provide an automated, precise
answer to this question.

Types serve as documentation for yourself and other programmers and provide a
‘gradient’ that tells you what terms make sense to write. For someone trained,
the types give a sense of what is expressible using any API. Like puzzle pieces
with shapes that we can observe fit together, we can think of types as
specifying a grammar for programs that ‘make sense’. In dynamic languages (what
Bob Harper somewhat trollishly refers to as ‘singly-typed’ languages),
information about what programs make sense needs to be communicated in other
ways. Example: many libraries have documentation with examples. Great. But if
one of the examples has the line read(message, peer), it’s often difficult to
ascertain whether a related expression, like read(fileChunkStream(file1), peer),
is also valid. Types provide immediate answers to these questions, especially
for someone trained at reading typeful APIs.


Benefits of static type checking and their alternatives, which implemented in thesis
\cite{staticvsdynamic}
\subsection{Disadvantages}
something here

Like any formalism, types require some investment up front to become fluent in.

Type errors are frequently poor. Thus, even though errors are caught sooner, the
way they are reported to the user can be frustratingly opaque, which isn’t good
for programmer motivation. In the world of static typing enthusiasts, there’s
also a segment of people who will state or imply that anyone who gets frustrated
by the user experience of fixing type errors is dumb, not a “real programmer”,
etc. There are also complexity apologists who will defend the “type error user
experience”.

Static typing is a constraint on your program’s structure. How limiting or
liberating these constraints are is up for debate, but some people will argue
it’s a big deal. Some tasks, especially around generic programming, can be very
easily expressed in a dynamic language, but require more machinery in a static
language. For instance, a generic serialization library can be written in a
dynamic language, without anything fancy, but providing the same thing in a
static language requires more machinery (see for instance Haskell’s generics
support), and is sometimes more complicated to use.

It can be difficult to assign static types to some programs, and learning how
best to carve a program up into types is a skill that takes years to master.
This is sort of a subtle point: when programming in a static language, you
always have a choice about what information you encode in the types, and how you
encode things. For instance, you can create and use a nonempty list type and
have the compiler check it statically or you can let nonemptiness be a dynamic
property that you have to check for at runtime. You can have lazy, potentially
infinite strings be a distinct type from strict, finite strings, or you can lump
both concepts into the same type. And so on. In a static language, you do always
have the option of building a less typeful API, where less is enforced by the
types, but it is often tempting to spend more time encoding things statically
(and then proving things to the typechecker) than would be saved by avoidance of
potential future bugs. With experience, you develop a good sense for what is
worth tracking statically and what to keep dynamic, but newcomers to static
languages can make bad tradeoffs here, which in turn contributes to needless
complexity in the language’s library ecosystem. Haskell has this problem IMO,
even though on the whole, I find Haskell has some very high quality libraries.

To put this last point another way, with static types, you have to make more
choices, and you may have to make these choices at a point in time where you’re
unsure how to decide, or when the choice feels distracting.

\section{Optional annotations}
What can be done prismatic.schema, clojure.spec
\subsection{prismatic.schema}
\subsection{clojure.spec}
Docs are not enough

Clojure is a dynamic language. Among other things this means that type
annotations are not required for code to run. While Clojure has some support for
type hints, they are not an enforcement mechanism, nor comprehensive, and are
limited to communicating information to the compiler to aid in efficient code
generation. Clojure gets runtime checking of a richer set of types by the JVM
itself.

However it has always been a guiding principle of Clojure, widely valued and
practiced by the community, to simply represent information as data. Thus
important properties of Clojure systems are represented and conveyed by the
shape and other predicative properties of the data, not captured or checked
anywhere since the runtime types are indistinguishable heterogeneous maps and
vectors.

Documentation strings can be used to communicate with human consumers, but they
can’t be leveraged by programs or tests, i.e. they have minimal power. Users
have turned to various libraries such as Schema and Herbert to get more powerful
specifications.

Map specs should be of keysets only

Most systems for specifying structures conflate the specification of the key set
(e.g. of keys in a map, fields in an object) with the specification of the
values designated by those keys. I.e. in such approaches the schema for a map
might say :a-key’s type is x-type and :b-key’s type is y-type. This is a major
source of rigidity and redundancy.

In Clojure we gain power by dynamically composing, merging and building up maps.
We routinely deal with optional and partial data, data produced by unreliable
external sources, dynamic queries etc. These maps represent various sets,
subsets, intersections and unions of the same keys, and in general ought to have
the same semantic for the same key wherever it is used. Defining specifications
of every subset/union/intersection, and then redundantly stating the semantic of
each key is both an antipattern and unworkable in the most dynamic cases.

Manual parsing and error reporting is not good enough

Many users, especially beginners, are frustrated and challenged by the error
messages produced by hand-written parsing and destructuring code, especially in
macros where there are two contexts of execution (the macro runs at compile time
and its expansion at runtime, either of which could fail due to user error).
This has led to a call for 'macro grammars', but in fact macros are just
functions of data $\rightarrow$ data and any solution for data validation and destructuring
should work as well for them as for any other functions. I.e. macros are an
instance of the problems above.

Generative testing and robustness

Finally, in all languages, dynamic or not, tests are essential to quality. Too
many critical properties are not captured by common type systems. But manual
testing has a very low effectiveness/effort ratio. Property-based, generative
testing, as implemented for Clojure in test.check, has proved to be far more
powerful than manually written tests.

Yet property based testing requires the definition of properties, which require
extra effort and expertise to produce, and which, at the function-level, have
substantial overlap with function specifications. Many interesting properties at
the function level would already be captured by structural+predicative specs.
Ideally, specs should integrate with generative testing and provide certain
categories of generative tests 'for free'.

A standard approach is needed. In short, Clojure has no standard, expressive,
powerful and integrated system for specification and testing. clojure.spec aims
to provide it.

Objectives

Communication

Species - appearance, form, sort, kind, equivalent to spec (ere) to look, regard
               + -is bstract noun suffix

Specify - species + -ficus -fic (make)
A specification is about how something 'looks', but is, most importantly, something that is looked at. Specs should be readable, composed of 'words' (predicate functions) programmers are already using, and integrated in documentation.

Unify specification in its various contexts

Specs for data structures, attribute values and functions should all be the same and live in a globally-namespaced directory.

Maximize leverage from specification effort

Writing a spec should enable automatic:

Validation
Error reporting
Destructuring
Instrumentation
Test-data generation
Generative test generation
Minimize intrusion

Don’t require that people e.g. define their functions differently. Minor modifications to doc and macroexpand will allow independently written specs to adorn fn/macro behavior without redefinition.

Decomplect maps/keys/values

Keep map (keyset) specs separate from attribute (key$\rightarrow$value) specs. Encourage and support attribute-granularity specs of namespaced keyword to value-spec. Combining keys into sets (to specify maps) becomes orthogonal, and checking becomes possible in the fully-dynamic case, i.e. even when no map spec is present, attributes (key-values) can be checked.

Enable and start a dialog about semantic change and compatibility

Programmers suffer greatly when they redefine things while keeping the names the same. Yet some changes are compatible and some are breaking, and most tools can’t distinguish. Use constructs like set membership and regular expressions for which compatibility can be determined, and provide tools for compatibility checking (while leaving general predicate equality out of scope).

Guidelines

Mistakes will be made

We don’t (and couldn’t) live in a world where we can’t make mistakes. Instead, we periodically check that we haven’t. Amazon doesn’t send you your TV via a UPS<Trucks<Boxes<TV>>>. So occasionally you might get a microwave, but the supply chain isn’t burdened with correctness proof. Instead we check at the edges and run tests.

expressivity > proof

There is no reason to limit our specifications to what we can prove, yet that is primarily what type systems do. There is so much more we want to communicate and verify about our systems. This goes beyond structural/representational types and tagging to predicates that e.g. narrow domains or detail relationships between inputs or between inputs and output. Additionally, the properties we care most about are often those of the runtime values, not some static notion. Thus spec is not a type system.

Names are important

All programs use names, even when the type systems don’t, and they capture important semantics. Int x Int x Int just isn’t good enough (is it length/width/height or height/width/depth?). So spec will not have unlabeled sequence components or untagged union bindings. The utility of this becomes evident when spec needs to talk to users about specs, e.g. in error reporting, and vice versa, e.g. when users want to override generators in specs. When all branches are named, you can talk about parts of specs using paths.

Global (namespaced) names are more important

Clojure supports namespaced keywords and symbols. Note here we are just talking about namespace-qualified names, not Clojure namespace objects. These are tragically underutilized and convey important benefits because they can always co-reside in dictionaries/dbs/maps/sets without conflict. spec will allow (only) namespace-qualified keywords and symbols to name specs. People using namespaced keys for their informational maps (a practice we’d like to see grow) can register the specs for those attributes directly under those names. This categorically changes the self-description of maps, particularly in dynamic contexts, and encourages composition and consistency.

Don’t further add to/overload the (reified) namespaces of Clojure

Nothing will be attached to vars, metadata etc. All functions have namespaced names which can serve as keys to their related data (e.g. spec) that is stored elsewhere.

Code is data (not vice versa)

In Lisps (and thus Clojure), code is data. But data is not code until you define a language around it. Many DSLs in this space drive at a data representation for schemas. But predicative specs have an open and large vocabulary, and most of the useful predicates already exist and are well known as functions in the core and other namespaces, or can be written as simple expressions. Having to 'datafy', possibly renaming, all of these predicates adds little value, and has a definite cost in understanding precise semantics. spec instead leverages the fact that the original predicates and expressions are data in the first place and captures that data for use in communicating with the users in documentation and error reporting. Yes, this means that more of the surface area of clojure.spec will be macros, but specs are overwhelmingly written by people and, when composed, manually so.

Sets (maps) are about membership, that’s it

As per above, maps defining the details of the values at their keys is a fundamental complecting of concerns that will not be supported. Map specs detail required/optional keys (i.e. set membership things) and keyword/attr/value semantics are independent. Map checking is two-phase, required key presence then key/value conformance. The latter can be done even when the (namespace-qualified) keys present at runtime are not in the map spec. This is vital for composition and dynamicity.

Informational vs implementational

Invariably, people will try to use a specification system to detail implementation decisions, but they do so to their detriment. The best and most useful specs (and interfaces) are related to purely information aspects. Only information specs work over wires and across systems. We will always prioritize, and where there is a conflict, prefer, the information approach.

K.I.S.S.

There are very few bottom notions in this space and we will endeavor to stick to them. There are few distinct structural notions - a handful of atomic types, sequential things, sets and maps. Unsurprisingly, these are the Clojure data types and fundamental ops will be provided only for these. Similarly there are mathematical tools for talking about these - set logic for maps and regular expressions for sequences - that have valuable properties. We will prefer these over ad hoc solutions.

Build on test.check but don’t require knowledge of it

The generative testing underpinning of spec will leverage test.check and not reinvent it. But spec users should not need to know anything about test.check until and unless they want to write their own generators or supplement spec's generated tests with further property-based tests of their own. There should be no production runtime dependency on test.check.

Features

Overview

Predicative specs

The basic idea is that specs are nothing more than a logical composition of
predicates. At the bottom we are talking about the simple boolean predicates you
are used to like int? or symbol?, or expressions you build yourself like $\#(<
42 \% 66)$. spec adds logical ops like spec/and and spec/or which combine specs in a logical way and offer deep reporting, generation and conform support and, in the case of spec/or, tagged returns.

Maps

Specs for map keysets provide for the specification of required and optional key sets. A spec for a map is produced by calling keys with :req and :opt keyword arguments mapping to vectors of key names.

:req keys support the logical operators and and or.

(spec/keys :req [::x ::y (or ::secret (and ::user ::pwd))] :opt [::z])
One of the most visible differences between spec and other systems is that there is no place in that map spec for specifying the values e.g. ::x can take. It is the (enforced) opinion of spec that the specification of values associated with a namespaced keyword, like :my.ns/k, should be registered under that keyword itself, and applied in any map in which that keyword appears. There are a number of advantages to this:

It ensures consistency for all uses of that keyword in an application where all uses should share a semantic
It similarly ensures consistency between a library and its consumers
It reduces redundancy, since otherwise many map specs would need to make matching declarations about k
Namespaced keyword specs can be checked even when no map spec declares those keys
This last point is vital when dynamically building up, composing, or generating maps. Creating a spec for every map subset/union/intersection is unworkable. It also facilitates fail-fast detection of bad data - when it is introduced vs when it is consumed.

Of course, many existing map-based interfaces take non-namespaced keys. To support connecting them to properly namespaced and reusable specs, keys supports -un variants of :req and :opt

(spec/keys :req-un [:my.ns/a :my.ns/b])
This specs a map that requires the unqualified keys :a and :b but validates and generates them using specs (when defined) named :my.ns/a and :my.ns/b respectively. Note that this cannot convey the same power to unqualified keywords as have namespaced keywords - the resulting maps are not self-describing.

Sequences

Specs for sequences/vectors use a set of standard regular expression operators, with the standard semantics of regular expressions:

cat - a concatenation of predicates/patterns
alt - a choice of one among a set of predicates/patterns
* - zero or more occurrences of a predicate/pattern
+ - one or more
? - one or none
\& - takes a regex op and further constrains it with one or more predicates
These nest arbitrarily to form complex expressions.

Note that cat and alt require all of their components be labeled, and the return value of each is a map with the keys corresponding to the matched components. In this way spec regexes act as destructuring and parsing tools.

% user=> (require '[clojure.spec :as s])
% (s/def ::even? (s/and integer? even?))
% (s/def ::odd? (s/and integer? odd?))
% (s/def ::a integer?)
% (s/def ::b integer?)
% (s/def ::c integer?)
% (def s (s/cat :forty-two #{42}
%               :odds (s/+ ::odd?)
%               :m (s/keys :req-un [::a ::b ::c])
%               :oes (s/* (s/cat :o ::odd? :e ::even?))
%               :ex (s/alt :odd ::odd? :even ::even?)))
% user=> (s/conform s [42 11 13 15 {:a 1 :b 2 :c 3} 1 2 3 42 43 44 11])
% {:forty-two 42,
%  :odds [11 13 15],
%  :m {:a 1, :b 2, :c 3},
%  :oes [{:o 1, :e 2} {:o 3, :e 42} {:o 43, :e 44}],
%  :ex {:odd 11}}
conform/explain

As you can see above, the basic operation for using specs is conform, which takes a spec and a value and returns the conformed value or :clojure.spec/invalid if the value did not conform. When the value does not conform you can call explain or explain-data to find out why it didn’t.

Defining specs

The primary operations for defining specs are s/def, s/and, s/or, s/keys and the regex ops. There is a spec function that can take a predicate function or expression, a set, or a regex op, and can also take an optional generator which would override the generator implied by the predicate(s).

Note however, that def, and, or, keys spec fns and the regex ops can all take and use predicate functions and sets directly - and do not need them to be wrapped by spec. spec should only be needed when you want to override a generator or to specify that a nested regex starts anew, vs being included in the same pattern.

Data spec registration

In order for a spec to be reusable by name, it has to be registered via def. def takes a namespace-qualified keyword/symbol and a spec/predicate expression. By convention, specs for data should be registered under keywords and attribute values should be registered under their attribute name keyword. Once registered, the name can be used anywhere a spec/predicate is called for in any of the spec operations.

Function spec registration

A function can be fully specified via three specs - one for the args, one for the return, and one for the operation of the function relating the args to the return.

The args spec for a fn is always going to be a regex that specs the arguments as if they were a list, i.e. the list one would pass to apply the function. In this way, a single spec can handle functions with multiple arities.

The return spec is an arbitrary spec of a single value.

The (optional) fn spec is a further specification of the relationship between the arguments and the return, i.e. the function of the function. It will be passed (e.g. during testing) a map containing {:args conformed-args :ret conformed-ret} and will generally contain predicates that relate those values - e.g. it could ensure that all keys of an input map are present in the returned map.

You can fully specify all three specs of a function in a single call to fdef, and recall the specs via fn-specs.

Using specs

Documentation

Functions specs defined via fdef will appear when you call doc on the fn name. You can call describe on specs to get descriptions as forms.

Parsing/destructuring

You can use conform directly in your implementations to get its destructuring/parsing/error-checking. conform can be used e.g. in macro implementations and at I/O boundaries.

During development

You can selectively instrument functions and namespaces with instrument, which swaps out the fn var with a wrapped version of the fn that tests the :args spec. unstrument returns a fn to its original version. You can generate data for interactive testing with gen/sample.

For testing

You can run a suite of spec-generative tests on an entire ns with check. You can get a test.check compatible generator for a spec by calling gen. There are built-in associations between many of the clojure.core data predicates and corresponding generators, and the composite ops of spec know how to build generators atop those. If you call gen on a spec and it is unable to construct a generator for some subtree, it will throw an exception that describes where. You can pass generator-returning fns to spec in order to supply generators for things spec does not know about, and you can pass an override map to gen in order to supply alternative generators for one or more subpaths of a spec.

At runtime

In addition to the destructuring use cases above, you can make calls to conform or valid? anywhere you want runtime checking, and can make lighter-weight internal-only specs for tests you intend to run in production.

Please see the spec Guide and API docs for more examples and usage information.

Glossary

predicates

Many parts of the spec API call for 'predicates' or 'preds'. These arguments can be satisfied by:

predicate (boolean) fns
sets
registered names of specs
specs (the return values of spec, and, or, keys)
regex ops (the return values of cat, alt, *, +, ?, \&)
Note that if you want to nest an independent regex predicate within a regex you will have to wrap it in a call to spec, else it will be considered a nested pattern.

specs

The return values of spec, and, or and keys.

regex ops

The return values of cat, alt, *, +, ?, \&. When nested these form a single expression.

conform

conform is the basic operation for consuming specs, and does both validation and conforming/destructuring. Note that conforming is 'deep' and flows through all of the spec and regex operations, map specs etc. Since nil and false are legitimate conformed values, conform returns the distinguished :clojure.spec/invalid when a value cannot be made to conform. valid? can be used instead as a fully-boolean predicate.

explain

When a value fails to conform to a spec you can call explain or explain-data with the same spec+value to find out why. These explanations are not produced during conform because they might perform additional work and there is no reason to incur that cost for non-failing inputs or when no report is desired. An important component of explanations is the path. explain extends the path as it navigates through e.g. nested maps or regex patterns, so you get better information than just the entire or leaf value. explain-data will return a map of paths to problems.

paths

Due to the fact that all branching points in specs are labeled, i.e. map keys, choices in or and alt, and (possibly elided) elements of cat, every subexpression in a spec can be referred to via a path (vector of keys) naming the parts. These paths are used in explain, gen overrides and various error reporting.

Prior Art

Almost nothing about spec is novel. See all the libraries mentioned above, RDF, as well as all the work done on various contract systems, such as Racket’s contracts.

I hope you find spec useful and powerful.

Rich Hickey

Better Communication

Clojure is a dynamic language, and thus far we have relied on documentation or external libraries to explain the use and behavior of functions and libraries. But documentation is difficult to produce, is frequently not maintained, cannot be automatically checked and varies greatly in quality. Specs are expressive and precise. Including spec in Clojure creates a lingua franca with which we can state how our programs work and how to use them.

More Leverage and Power

A key advantage of specifications over documentation is the leverage they provide. In particular, specs can be utilized by programs in ways that docs cannot. Defining specs takes effort, and spec aims to maximize the return you get from making that effort. spec gives you tools for leveraging specs in documentation, validation, error reporting, destructuring, instrumentation, test-data generation and generative testing.

Improved Developer Experience

Error messages from macros are a perennial challenge for new (and experienced) users of Clojure. Specs can be used to conform data in macros instead of using a custom parser. And Clojure’s macro expansion will automatically use specs, when present, to explain errors to users. This should result in a greatly improved experience for users when errors occur.

More Robust Software

Clojure has always been about simplifying the development of robust software. In all languages, dynamic or not, tests are essential to quality - too many critical properties are not captured by common type systems. spec has been designed from the ground up to directly support generative testing via test.check. When you use spec you get generative tests for free.

Taken together, I think the features of spec demonstrate the ongoing advantages of a powerful dynamic language like Clojure for building robust software - superior expressivity, instrumentation-enhanced REPL-driven development, sophisticated testing and more flexible systems. I encourage you to read the spec rationale and overview. Look for spec’s inclusion in the next alpha release of Clojure, within a day or so.



\section{Gradual typing}
\subsection{TypedClojure}
TypedClojure, pros and cons
\cite{bonnaire2016practical}
The popularity of dynamically-typed languages in software development, combined
with a recognition that types often improve programmer productivity,
software reliability, and performance, has led to the recent development of a wide
variety of optional and gradual type systems aimed at checking existing programs
written in existing languages. These include TypeScript [19] and Flow [11] for
JavaScript, Hack [10] for PHP, and mypy [15] for Python among the optional
systems, and Typed Racket [23], Reticulated Python [25], and GradualTalk [1]
among gradually-typed systems.1


One key lesson of these systems, indeed a lesson known to early developers of
optional type systems such as StrongTalk, is that type systems for existing
languages must be designed to work with the features and idioms of the target
language. Often this takes the form of a core language, be it of functions or
classes and objects, together with extensions to handle distinctive language
features. We synthesize these lessons to present Typed Clojure, an optional type
system for Clojure. Clojure is a dynamically typed language in the Lisp
family—built on the Java Virtual Machine (JVM)—which has recently gained
popularity as an alternative JVM language. It offers the flexibility of a Lisp
dialect, including macros, emphasizes a functional style via immutable data
structures, and provides interoperability with existing Java code, allowing
programmers to use existing Java libraries without leaving Clojure. Since its
initial release in 2007, Clojure has been widely adopted for “backend”
development in places where its support for parallelism, functional programming,
and Lisp-influenced abstraction is desired on the JVM. As a result, there is an
extensive base of existing untyped programs whose developers can benefit from
Typed Clojure, an experience we discuss in this paper. Since Clojure is a
language in the Lisp family, we apply the lessons of Typed Racket, an existing
gradual type system for Racket, to the core of Typed Clojure, consisting of an
extended lambda-calculus over a variety of base types shared between all Lisp
systems. Furthermore, Typed Racket’s occurrence typing has proved necessary for
type checking realistic Clojure programs. However, Clojure goes beyond Racket in
many ways, requiring several new type system features which we detail in this
paper. Most significantly, Clojure supports, and Clojure developers use,
multimethods to structure their code in extensible fashion. Furthermore, since
Clojure is an untyped language, dispatch within multimethods is determined by
application of dynamic predicates to argument values. Fortunately, the dynamic
dispatch used by multimethods has surprising symmetry with the conditional
dispatch handled by occurrence typing. Typed Clojure is therefore able to
effectively handle complex and highly dynamic dispatch as present in existing
Clojure programs. But multimethods are not the only Clojure feature crucial to
type checking existing programs. As a language built on the Java Virtual
Machine, Clojure provides flexible and transparent access to existing Java
libraries, and Clojure/Java interoperation is found in almost every significant
Clojure code base. Typed Clojure therefore builds in an understanding of the
Java type system and handles interoperation appropriately. Notably, null is a
distinct type in Typed Clojure, designed to automatically rule out null-pointer
exceptions. An example of these features is given in Figure 1. Here, the pname
multimethod dispatches on the class of the argument—for Strings, the first
method implementation is called, for Files, the second. The String method calls
a File constructor, returning a non-nil File instance—the getName method on File
requires a non-nil target, returning a nilable type. Finally, flexible,
high-performance immutable dictionaries are the most common Clojure data
structure. Simply treating them as uniformly-typed key-value mappings would be
insufficient for existing programs and programming styles. Instead, Typed
Clojure provides a flexible heterogenous map type, in which specific entries can
be specified. While these features may seem disparate, they are unified in
important ways. First, they leverage the type system mechanisms inherited from
Typed Racket— multimethods when using dispatch via predicates, Java
interoperation for handling null tests, and heterogenous maps using union types
and reasoning about subcomponents of data. Second, they are crucial features for
handling Clojure code in practice. Typed Clojure’s use in real Clojure
deployments would not be possible without effective handling of these three
Clojure features. Our main contributions are as follows: 1. We motivate and
describe Typed Clojure, an optional type system for Clojure that understands
existing Clojure idioms. 2. We present a sound formal model for three crucial
type system features: multi-methods, Java interoperability, and heterogenous
maps. 3. We evaluate the use of Typed Clojure features on existing Typed Clojure
code, including both open source and in-house systems. The remainder of this
paper begins with an example-driven presentation of the main type system
features in Section 2. We then incrementally present a core calculus for Typed
Clojure covering all of these features together in Section 3 and prove type
soundness (Section 4). We then present an empirical analysis of significant code
bases written in core.typed—the full implementation of Typed Clojure—in Section
5. Finally, we discuss related work and conclude.

\subsection{Spectrum}
Introducing Spectrum (github.com/arohner/spectrum), a static “typing”
library that statically checks clojure code using standard clojure.spec
annotations.

%\section{Draft figures}

% We can include encapsulated PostScript\texttrademark\ figures
% (\texttt{.eps}) in the document and refer to it using a label.
% For example, MUN's logo can be seen in Figure~\ref{fig:MUN_Logo_Pantone}.
% \munepsfig{MUN_Logo_Pantone}{This is MUN's logo}

% Figure~\ref{fig:enrollment} shows a chart of MUN's Fall
% enrollment from 2005 -- 2009.\munfootnote{From \emph{Memorial
% University of Newfoundland --- Fact Book 2009}.}
% \munepsfig[scale=0.50]{enrollment}{MUN Fall Enrollment 2005 -- 2009}
% The figure was created using the \textsf{Calc} spreadsheet application of
% the office suite \textsf{OpenOffice.org}.\munfootnote{This office suite
% can be downloaded at no cost from \texttt{http://openoffice.org/}. Unlike
% other commercial office suites, \textsf{OpenOffice.org} may be legally
% shared with colleagues and fellow students.  There are versions for
% Linux, Microsoft Windows, Mac~OS~X and Solaris.  Also, unlike commercial
% offerings, \textsf{OpenOffice.org} does not require activation using
% registration keys.}  This figure was reduced by 50\%.

% For larger figures, we can use landscape mode to rotate the page
% and display the figure using the \verb+\munlepsfig+ command, as shown
% in Figure~\ref{fig:enrollment-landscape}.  The figure will be the
% only thing on the page when typeset in landscape mode.
% (The figure is reduced to 85\% of its original size.)
% \munlepsfig[scale=0.85]{enrollment-landscape}
% 	{MUN Fall Enrollment 2005 -- 2009 (landscape)}

% Alternatively, if we just want to rotate the figure, but not
% the entire page, we can specify an \texttt{angle} attribute
% in the default argument of the \verb+\munepsfig+ command.
% The result is shown in Figure~\ref{fig:enrollment-rotate}.
% If the figure is too large or if there isn't sufficient
% text, then the figure may appear on its own page.
% \munepsfig[scale=0.30,angle=90]{enrollment-rotate}
% 	{MUN Fall Enrollment 2005 -- 2009 (rotated)}

% Note that all three of the enrollment figures are basically
% the same file, but with different names --- on Linux, they are
% symbolic links to the same file.  The filenames have to be different
% because the reference labels need to be unique.

% Figure~\ref{fig:db-deadlock} shows a Petri net created using the
% \texttt{xfig} program (\texttt{http://www.xfig.org/}) which has
% very good support for \LaTeX.  This figure has been
% reduced to 40\% of its original size.
% \munepsfig[scale=0.40]{db-deadlock}{A deadlocked Petri net}

% We can also create figures of text (such as short code snippets)
% using the \verb+\muntxtfig+ command, as show in Figure~\ref{fig:code}.
% \begin{muntxtfig}[1.0]{code}{Hello World}{0.5\textwidth}
% \begin{verbatim}
% #include <stdio.h>

% int main(int argc, char **argv)
% {
%   printf("Hello world!\n");
%   exit(0);
% }
% \end{verbatim}
% \end{muntxtfig}

% %\section{Draft Tables}

% We can also create tables, as seen by Table~\ref{tab:pop}.  Note that,
% as required by SGS guidelines, the caption for a table appears above the
% table whereas figure captions appear below the figures.  Tables and
% figures can ``float'' --- they may not appear on the page on which they
% are mentioned.  \LaTeX{} tries to handle figure and table placement
% intelligently, but if if you have a lot of them without a reasonable
% amount of surrounding textual content, the figures and tables can
% accumulate towards the end of the chapter.  Generally speaking, if
% there is sufficient text explaining the tables and figures or if the
% tables/figures are relatively small, this may not be a problem.  However,
% if you have a lot of tables or figures, it may be a good idea to put
% them in an appendix and refer to them as the need arises.

% \begin{muntab}{c||c|c|c||c|c|c|}{pop}{Fall Semester Enrollment}
% \hline
% 	& \multicolumn{3}{c||}{Undergraduate}
% 	& \multicolumn{3}{c|}{Graduate} \\
% \cline{2-7}
%      & F/T & P/T & Total & F/T & P/T & Total \\
% \cline{2-7}
% 2004 & 13,191 & 2,223 & 15,414 & 1,308 & 879 & 2,187 \\
% 2005 & 13,184 & 2,143 & 15,327 & 1,375 & 920 & 2,295 \\
% 2006 & 12,809 & 2,224 & 15,033 & 1,373 & 899 & 2,272 \\
% 2007 & 12,634 & 2,155 & 14,789 & 1,403 & 899 & 2,302 \\
% 2008 & 12,269 & 2,208 & 14,477 & 1,410 &1,005& 2,415 \\
% 2009 & 12,382 & 2,323 & 14,705 & 1,567 &1,106& 2,673 \\
% \hline
% \end{muntab}

% Table~\ref{tab:degrees} shows a different table in landscape
% mode.\munfootnote{This data was also taken from the \emph{Memorial
% University of Newfoundland --- Fact Book 2009}.} This is useful if your
% table is too wide for the page.  Tables are double-spaced by default.
% To single-space a table, change the \verb+\baselinestretch+ before
% beginning the table environment.  Remember to restore it after the
% environment has ended.

% \renewcommand{\baselinestretch}{1.0}\normalsize
% \begin{munltab}{lrrrrrrrrrrrr}
% 	{degrees}
% 	{Masters Degrees Conferred by Convocation Session --- 1950 to 2009}
% \cline{2-13}
% 				&
% \multicolumn{2}{|c|}{2009}	&
% \multicolumn{2}{c|}{2008}	&
% \multicolumn{2}{c|}{2007}	&
% \multicolumn{2}{c|}{2006}	&
% \multicolumn{2}{c|}{2006}	&
% \multicolumn{1}{c|}{1950--2004}	&
% \multicolumn{1}{c|}{Total}	\\
% \cline{2-13}
% 	  &
% May & Oct &
% May & Oct &
% May & Oct &
% May & Oct &
% May & Oct & &  \\
% Degrees \\
% \hline
% Master of Applied Science		&  14 &   2 &  15 &   8 &  28 &   1 &  21 &   3 &   3 &   1 &    98 &   194 \\
% Master of Applied Social Psychology     &   1 &   5 &   2 &   5 &   1 &   4 &   0 &   4 &   0 &   4 &    28 &    54 \\
% Master of Applied Statistics            &   0 &   0 &   3 &   1 &   0 &   0 &   1 &   0 &   0 &   0 &    19 &    24 \\
% Master of Arts                          &  37 &  49 &  26 &  43 &  14 &  42 &  14 &  56 &  13 &  44 &   994 & 1,332 \\
% Master of Business Administration       &  14 &  16 &  23 &   6 &  33 &  12 &  33 &  11 &  33 &   8 &   818 & 1,007 \\
% Master of Education                     & 107 &  87 & 120 &  55 & 147 &  74 & 108 &  76 & 113 &  75 & 2,603 & 3,565 \\
% Master of Employment Relations          &   8 &   9 &   5 &   7 &   7 &  14 &   4 &   9 &   3 &   5 &    12 &    83 \\
% Master of Engineering                   &  20 &  19 &  20 &  10 &  16 &  10 &  15 &  13 &   4 &  19 &   440 &   586 \\
% Master of Environmental Science         &   3 &   3 &   3 &   1 &   0 &   1 &   7 &   1 &   3 &   1 &    66 &    89 \\
% Master of Marine Studies                &   2 &   0 &   0 &   1 &   0 &   2 &   2 &   2 &   1 &   2 &    26 &    38 \\
% Master of Music                         &   4 &   1 &   5 &   0 &   3 &   0 &   3 &   0 &   3 &   0 &     7 &    26 \\
% Master of Nursing                       &   7 &   8 &  10 &   4 &  17 &   4 &  23 &   7 &   6 &   1 &   116 &   203 \\
% Master of Oil and Gas Studies           &   0 &   0 &   2 &   0 &   0 &   0 &   0 &   2 &   4 &   0 &     0 &     8 \\
% Master of Philosophy                    &   5 &   4 &   2 &   1 &   5 &   2 &   5 &   3 &   2 &   0 &   112 &   141 \\
% Master of Physical Education            &   0 &   2 &   3 &   0 &   5 &   4 &   3 &   0 &   4 &   4 &    84 &   109 \\
% Master of Public Health                 &   0 &   8 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &     0 &     8 \\
% Master of Science                       &  40 &  32 &  41 &  19 &  29 &  25 &  35 &  29 &  32 &  23 & 1,653 & 1,958 \\
% Master of Science (Kinesiology)         &   1 &   0 &   4 &   2 &   1 &   2 &   2 &   6 &   4 &   3 &     0 &    25 \\
% Master of Science (Medicine)            &  18 &   7 &  11 &   8 &  10 &   5 &   9 &   9 &   8 &   4 &     0 &    89 \\
% Master of Science (Pharmacy)            &   0 &   0 &   1 &   1 &   0 &   0 &   0 &   0 &   1 &   0 &    16 &    19 \\
% Master of Social Work                   &   4 &  11 &   4 &   5 &   4 &   9 &   9 &   5 &   4 &  10 &   257 &   322 \\
% Master of Women's Studies               &   2 &   0 &   2 &   0 &   1 &   1 &   2 &   3 &   2 &   0 &    20 &    33 \\
% \hline
% \textbf{Total Masters}                  & 287 & 263 & 302 & 177 & 321 & 212 & 296 & 239 & 243 & 204 & 7,369 & 9,913 \\
% \end{munltab}
% \renewcommand{\baselinestretch}{\spacing}\normalsize
